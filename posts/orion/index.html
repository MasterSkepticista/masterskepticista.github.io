<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#FFFFFF"><title>Data Parallelism using standard Ethernet &#183; MasterSkepticista</title>
<meta name=title content="Data Parallelism using standard Ethernet &#183; MasterSkepticista"><script type=text/javascript src=/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.eaf5efab3f4188a116dda7ffc5498d61662733eaf22fa6a2fcb554efa84c23c8.css integrity="sha256-6vXvqz9BiKEW3af/xUmNYWYnM+ryL6ai/LVU76hMI8g="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.90a48a144b2de1542549eda42e3a5a686046f98731a313b07209f4432d7f0946.js integrity="sha256-kKSKFEst4VQlSe2kLjpaaGBG+YcxoxOwcgn0Qy1/CUY=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        Bag-of-tricks for multi-node training for the GPU Poor.
      
    "><link rel=canonical href=https://masterskepticista.github.io/posts/orion/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://masterskepticista.github.io/posts/orion/"><meta property="og:site_name" content="MasterSkepticista"><meta property="og:title" content="Data Parallelism using standard Ethernet"><meta property="og:description" content="Bag-of-tricks for multi-node training for the GPU Poor."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-05T00:00:00+00:00"><meta property="article:tag" content="Data Parallelism"><meta property="article:tag" content="Multi-Node"><meta property="article:tag" content="Jax"><meta property="article:tag" content="Tensorflow"><meta property="article:tag" content="Pytorch"><meta name=twitter:card content="summary"><meta name=twitter:title content="Data Parallelism using standard Ethernet"><meta name=twitter:description content="Bag-of-tricks for multi-node training for the GPU Poor."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Data Parallelism using standard Ethernet","headline":"Data Parallelism using standard Ethernet","abstract":"Bag-of-tricks for multi-node training for the GPU Poor.","inLanguage":"en","url":"https:\/\/masterskepticista.github.io\/posts\/orion\/","author":{"@type":"Person","name":"Karan Shah"},"copyrightYear":"2024","dateCreated":"2024-08-05T00:00:00\u002b00:00","datePublished":"2024-08-05T00:00:00\u002b00:00","dateModified":"2024-08-05T00:00:00\u002b00:00","keywords":["data parallelism","multi-node","jax","tensorflow","pytorch"],"mainEntityOfPage":"true","wordCount":"1632"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://masterskepticista.github.io/","name":"","position":1},{"@type":"ListItem","item":"https://masterskepticista.github.io/posts/","name":"Posts","position":2},{"@type":"ListItem","name":"Data Parallelism Using Standard Ethernet","position":3}]}</script><meta name=author content="Karan Shah"><link href=https://github.com/MasterSkepticista rel=me><link href=https://twitter.com/elevated_quark rel=me><link href="https://scholar.google.com/citations?user=vEgcRTkAAAAJ&amp;hl=en" rel=me><link href=https://stackoverflow.com/users/9230398/karan-shah rel=me><link href=https://linkedin.com/in/karan-bhavesh-shah rel=me><link type=text/css rel=stylesheet href=/lib/katex/katex.min.68e17230ccd917b97b7a2def38a8108918599d8aa4f580bfb8cce5e13d23e4de43dcaba5f9000553cb2c10d0d1300aabfe5c433a3305ebd752609f0762a63e59.css integrity="sha512-aOFyMMzZF7l7ei3vOKgQiRhZnYqk9YC/uMzl4T0j5N5D3Kul+QAFU8ssENDRMAqr/lxDOjMF69dSYJ8HYqY+WQ=="><script defer src=/lib/katex/katex.min.50f14e69d6a8da7128ae3b63974c544ed377c36d096b5e3750f114e84c89d668b9301d9b0ed3248969aa183aa2e3bc4d2c1e73d5dcb7d462890c45a18d424589.js integrity="sha512-UPFOadao2nEorjtjl0xUTtN3w20Ja143UPEU6EyJ1mi5MB2bDtMkiWmqGDqi47xNLB5z1dy31GKJDEWhjUJFiQ=="></script><script defer src=/lib/katex/auto-render.min.6095714e3aadb63b14ddc4af69346ab12974c1b460654345f8d1860a0b68fcc51b22f68b757433193090bb80afc8965b65cb607e5541d0f5f0f4b2e64d69b9ff.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" onload=renderMathInElement(document.body)></script></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden"><nav class="flex items-start justify-between sm:items-center"><div class="z-40 flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>MasterSkepticista</a></div><label id=menu-button for=menu-controller class="block sm:hidden"><input type=checkbox id=menu-controller class=hidden><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="invisible fixed inset-0 z-30 m-auto h-full w-full cursor-default overflow-auto bg-neutral-100/50 opacity-0 backdrop-blur-sm transition-opacity dark:bg-neutral-900/50"><ul class="mx-auto flex w-full max-w-7xl list-none flex-col overflow-visible px-6 py-6 text-end sm:px-14 sm:py-10 sm:pt-10 md:px-24 lg:px-32"><li class=mb-1><span class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class="group mb-1"><a href=/posts/ title=Posts onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">blog</span></a></li><li class="group mb-1"><a href=/code/ title=Code onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">code</span></a></li><li class="group mb-1"><a href=/talks/ title=slides onclick=close_menu()><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">slides</span></a></li><li class="group mb-1"><button id=search-button-1 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li></ul></div></label><ul class="hidden list-none flex-row text-end sm:flex"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">blog</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/code/ title=Code><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">code</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><a href=/talks/ title=slides><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">slides</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0"><button id=search-button-2 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="hidden inline"><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/></a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/posts/>Posts</a><span class="px-1 text-primary-500">/</span></li><li class="hidden inline"><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/posts/orion/>Data Parallelism using standard Ethernet</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Data Parallelism using standard Ethernet</h1><div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2024-08-05 00:00:00 +0000 UTC">5 August 2024</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">8 mins</span></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 lg:sticky lg:top-10 print:hidden"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#infrastructure>Infrastructure</a></li><li><a href=#goals>Goals</a></li><li><a href=#single-gpu-training-baseline>Single GPU Training: Baseline</a><ul><li><a href=#bandwidth-calculation>Bandwidth Calculation</a></li></ul></li><li><a href=#multi-gpu-training-baseline>Multi GPU Training: Baseline</a></li><li><a href=#1-reducing-communication>1. Reducing Communication</a></li><li><a href=#2-deferring-communication>2. Deferring Communication</a></li><li><a href=#3-faster-communication>3. Faster Communication</a></li><li><a href=#result>Result</a></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><div class="lead !mb-9 text-xl">Big model ask big money.</div><p>The limiting factor on the size of models that can be trained, can be summarized to data movement speeds - either within the GPU (HBM bandwidth) or across GPUs (collective ops bandwidth). A big part of model scaling with the number of accelerators is achieved by reducing communication overhead across them. This is why protocols like Infiniband/NVLink exist.</p><p>But can we get away without spending a fortune on 100G/400G NICs for training models across nodes? Turns out, under the right assumptions, we can.</p><h2 id=infrastructure class="relative group">Infrastructure <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#infrastructure aria-label=Anchor>#</a></span></h2><p>We had four<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> server blades each with the following spec:</p><ul><li>Dual socket Xeon 6258R (28C/56T per socket)</li><li>512GB DDR4 Memory</li><li>One RTX-3090 GPU</li><li>Intel X540 Dual-port 10GbE, one of the ports was utilized for Internet via a 1GbE link.</li></ul><h2 id=goals class="relative group">Goals <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#goals aria-label=Anchor>#</a></span></h2><p>We had to consolidate these servers into a multi-node training cluster:</p><ul><li>With above <strong>90%</strong> scaling factor.</li><li>With support for medium sized models (think ResNet-50/101 or ViT-S/B) up to 100M params.</li><li>Using 10G Ethernet only. Any other NIC would require a new switch and a new card.</li></ul><p>The constraint: spend $0.</p><h2 id=single-gpu-training-baseline class="relative group">Single GPU Training: Baseline <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#single-gpu-training-baseline aria-label=Anchor>#</a></span></h2><p>Our focus was on data-parallel training since we could fit all our models on a single GPU (modulo tuning the batch size).</p><p>Take ResNet50 for example. Training a ResNet50 on 90 epochs of ImageNet-1k on a single blade takes 48h in the default <code>TensorFloat32</code> precision. Since Ampere+ architectures support <code>bfloat16</code>, we could reduce data movement within the GPU, and saturate the Tensor Cores (Tesla architecture supports <code>float16</code>, but that requires gradient scaling in the training loop to avoid overflows. I won&rsquo;t cover that here given there exist plenty of guides online on how to use <code>float16</code>).</p><p>Here is a summary of changes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># JAX</span>
</span></span><span class=line><span class=cl><span class=n>conv</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>jnp</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>dense</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>jnp</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TensorFlow (keras)</span>
</span></span><span class=line><span class=cl><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>mixed_precision</span><span class=o>.</span><span class=n>set_global_policy</span><span class=p>(</span><span class=s1>&#39;mixed_bfloat16&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Torch</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>autocast</span><span class=p>(</span><span class=n>device_type</span><span class=o>=</span><span class=n>device_type</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=o>...</span>
</span></span></code></pre></div><p>We wrote our training pipelines in TensorFlow + JAX for two main reasons:</p><ul><li>Fine-grained data ETL tuning with <code>tf.data</code>, and</li><li>Higher GPU throughput via XLA. This frees us from low-level compiler optimizations. (If you are a PyTorch user, <code>torch.compile</code> will do this for you)</li></ul><p>Half-precision matmuls got us down to 25h while hitting the same Top-1 score of 76.3%. We clocked a per-step time \(T_s=230\text{ms}\) (i.e. time taken per forward/backward pass of a batch). This was a reasonable single GPU baseline.</p><p>At this point we can extrapolate to our &ldquo;ideal&rdquo; cluster: it would train a ResNet50 just <strong>below 6.3h with 100% scaling</strong> across four nodes.</p><h3 id=bandwidth-calculation class="relative group">Bandwidth Calculation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#bandwidth-calculation aria-label=Anchor>#</a></span></h3><p>Training across nodes requires taking a global average of gradients across all GPUs on each backward pass. So each GPU would have to send and receive a full set of <code>gradient_size</code> data at each step.</p><p>$$
\text{gradient\_size} = \frac{\text{params\_size}}{1e^6} \times \text{bytes\_per\_param}
$$</p><p>For a ResNet50 with 25M parameters, <code>gradient_size</code> is roughly 100MB per step, per GPU. Since each GPU needs a full copy of globally averaged gradients - a naive algorithm would require the lead host to <code>fetch</code> and <code>broadcast</code> 100MB data to/from each GPU. This would create a massive bottleneck on the main host, since the communication time would grow linearly on the number of GPUs.</p><p>Lucky for us, most implementations<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> of collectives today use the <code>RingAllReduce</code> algorithm, which amortizes the amount of transfers as number of GPUs increase, by communicating &lsquo;chunked&rsquo; gradients. In other words: data communicated per GPU reaches an asymptotic limit, independent of the number of GPUs in the cluster.</p><p>$$
\text{data\_per\_gpu} = 2 (N - 1) \frac{\text{gradient\_size}}{N} = \frac{3}{2} \times 100 \text{ MB}
$$</p><p>If you are interested in the proof, Gibiansky has a great article explaining the <a href=https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/ target=_blank rel=noreferrer><code>RingAllReduce</code></a> algorithm.</p><div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900"><span class="pe-3 text-primary-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 0C114.6.0.0 114.6.0 256s114.6 256 256 256 256-114.6 256-256S397.4.0 256 0zm0 128c17.67.0 32 14.33 32 32 0 17.67-14.33 32-32 32s-32-14.3-32-32 14.3-32 32-32zm40 256h-80c-13.2.0-24-10.7-24-24s10.75-24 24-24h16v-64h-8c-13.25.0-24-10.75-24-24s10.8-24 24-24h32c13.25.0 24 10.75 24 24v88h16c13.25.0 24 10.75 24 24s-10.7 24-24 24z"/></svg>
</span></span><span class=dark:text-neutral-300>In complex topologies spanning thousands of GPUs, a <a href=https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2-4/ target=_blank rel=noreferrer><code>HierarchicalAllReduce</code></a> algorithm scales better.</span></div><p>On our 4-node cluster with 10GbE bi-directional links, time spent in communication would be</p><p>$$
T_c = \frac{\text{data\_per\_gpu}}{\text{bandwidth}} = \frac{150}{1.25 \times 1024} = 0.11 \text{s.}
$$</p><p>So we would pay a fixed cost of 110ms each time, to synchronize gradients.</p><h2 id=multi-gpu-training-baseline class="relative group">Multi GPU Training: Baseline <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#multi-gpu-training-baseline aria-label=Anchor>#</a></span></h2><p>Lets start with a simple baseline that connects all 4 blades through a 10G switch. We can measure the time spent in computation and communication using Tensorboard profiler.</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/orion/tb_prof_overview.png alt="Step profile of ResNet50" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Step profile of ResNet50</figcaption></figure><p>With a total forward + backward pass time \(T_s = 234\text{ms}\), we spend an additional \(T_c = 106\text{ms}\) in communication (&ldquo;NCCL&rdquo;), in line with our estimate above. Note that we already save time prefetching batches to the GPU by overlapping it with computation (&ldquo;Copy&rdquo; step).
With this information, we can calculate the scaling efficiency \(\eta\) of our cluster.</p><p>$$
\eta = \frac{T_s}{T_s + T_c} \approx 68.8%
$$</p><p>Now, our ResNet50 takes 9.1h to train (i.e., a \(2.74\times\) speedup over single GPU baseline). It is a sizeable jump, but notice that more than 1 GPU worth of our compute is spent idling.</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/orion/baseline.png alt="Scaling efficiency baseline" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Scaling efficiency baseline</figcaption></figure><p>If we take a close look at the formulation of \(\eta\), we only have two ways to increase scaling efficiency from here:</p><ol><li>Reduce communication (\(T_c\)), and/or</li><li>Defer communication (by increasing \(T_s\)).</li></ol><p>We will now explore each optimization in detail.</p><h2 id=1-reducing-communication class="relative group">1. Reducing Communication <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#1-reducing-communication aria-label=Anchor>#</a></span></h2><p>Upto this point we communicate 25M <code>float32</code> values at the end of each step. One way to reduce communication could be by compressing gradients (lossy or otherwise). Here are our options:</p><ol><li>Cast gradients to <code>bfloat16</code>: No risk of overflow, but lossy due to high machine \(\epsilon\)<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>.</li><li>Cast gradients to <code>float16</code>: Risk of overflow, but lossless if renormalized.</li><li>Use a more intelligent gradient compression schema (like sparsity?).</li></ol><p>We&rsquo;ll stick with a simple technique that worked for us. We cast gradients to <code>bfloat16</code> during communication. We did not observe any loss in accuracy.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># JAX</span>
</span></span><span class=line><span class=cl><span class=n>grads</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>g</span><span class=p>:</span> <span class=n>g</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>jnp</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>),</span> <span class=n>grads</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>grads</span> <span class=o>=</span> <span class=n>lax</span><span class=o>.</span><span class=n>pmean</span><span class=p>(</span><span class=n>grads</span><span class=p>,</span> <span class=n>axis_name</span><span class=o>=</span><span class=s2>&#34;batch&#34;</span><span class=p>)</span>  <span class=c1># AllReduce</span>
</span></span><span class=line><span class=cl><span class=n>grads</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>g</span><span class=p>:</span> <span class=n>g</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>jnp</span><span class=o>.</span><span class=n>float32</span><span class=p>),</span> <span class=n>grads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Tensorflow (Keras)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compressed_aggregate_gradients</span><span class=p>(</span><span class=n>grads_and_vars</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;An override for `tf.optimizers.Optimizer.aggregate_gradients` method to 
</span></span></span><span class=line><span class=cl><span class=s2>  compress gradients before allreduce.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>grads</span><span class=p>,</span> <span class=nb>vars</span> <span class=o>=</span> <span class=nb>zip</span><span class=p>(</span><span class=o>*</span><span class=n>grads_and_vars</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>grads</span> <span class=o>=</span> <span class=p>[</span><span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>g</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span> <span class=k>for</span> <span class=n>g</span> <span class=ow>in</span> <span class=n>grads</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>grads</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>distribute</span><span class=o>.</span><span class=n>get_replica_context</span><span class=p>()</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>tf</span><span class=o>.</span><span class=n>distribute</span><span class=o>.</span><span class=n>ReduceOp</span><span class=o>.</span><span class=n>SUM</span><span class=p>,</span> <span class=n>grads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>grads</span> <span class=o>=</span> <span class=p>[</span><span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>g</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span> <span class=k>for</span> <span class=n>g</span> <span class=ow>in</span> <span class=n>grads</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>grads_and_vars</span> <span class=o>=</span> <span class=nb>zip</span><span class=p>(</span><span class=n>grads</span><span class=p>,</span> <span class=nb>vars</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>grads_and_vars</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>aggregate_gradients</span> <span class=o>=</span> <span class=n>compressed_aggregate_gradients</span>
</span></span></code></pre></div><p>Our scaling efficiency with halved communication time is:</p><p>$$
\eta = \frac{T_s}{T_s + 0.5 \times T_c} = \frac{234}{234 + 53} \approx 81.5\%
$$</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/orion/gcompression.png alt="Gradient compression results" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Gradient compression results</figcaption></figure><p>&mldr;which is pretty neat! This brings down our training time from 9.1h to 7.7h.</p><h2 id=2-deferring-communication class="relative group">2. Deferring Communication <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#2-deferring-communication aria-label=Anchor>#</a></span></h2><p>Gradient synchronization is required at the end of each batch, and there are only so many samples we can fit in a single forward/backward pass per batch&mldr;</p><p>&mldr;or can we?</p><p>Gradient accumulation is a common technique to emulate large batch sizes on GPUs with limited memory. But this can also be seen as a way of deferring communication. If the maximum batch size supported on a forward/backward pass is 512, which was the case for us here, we could prepare a larger 1024-size batch, and sum over gradients within the GPU with two &ldquo;micro&rdquo; batches.</p><p>The only potential downside of this trick, is if a given model/optimizer does <em>not</em> scale with batch size. This could be the case for small datasets (but then why would you need data parallel?).</p><p>Here is a simple implementation in JAX:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>accumulate_gradient</span><span class=p>(</span><span class=n>value_and_grad_fn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>params</span><span class=p>:</span> <span class=n>PyTree</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=p>:</span> <span class=n>PyTree</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>accum_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>jnp</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>PyTree</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Accumulates gradients over given steps.
</span></span></span><span class=line><span class=cl><span class=s2>  
</span></span></span><span class=line><span class=cl><span class=s2>  Args:
</span></span></span><span class=line><span class=cl><span class=s2>    value_and_grad_fn: Gradient function that does not return aux values.
</span></span></span><span class=line><span class=cl><span class=s2>    params: Parameters, passed as first argument to `value_and_grad_fn`.
</span></span></span><span class=line><span class=cl><span class=s2>    batch: Batch, passed as second argument to `value_and_grad_fn`.
</span></span></span><span class=line><span class=cl><span class=s2>    accum_steps: Number of micro batches to accumulate over. Defaults to 1,
</span></span></span><span class=line><span class=cl><span class=s2>      which means no gradients are accumulated.
</span></span></span><span class=line><span class=cl><span class=s2>  
</span></span></span><span class=line><span class=cl><span class=s2>  Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    Tuple (loss, grads).
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>accum_steps</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>bs</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=nb>iter</span><span class=p>(</span><span class=n>jax</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>leaves</span><span class=p>(</span><span class=n>batch</span><span class=p>)))</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>bs</span> <span class=o>%</span> <span class=n>accum_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;Invalid accum_steps </span><span class=si>{</span><span class=n>accum_steps</span><span class=si>}</span><span class=s2> for batch size `</span><span class=si>{</span><span class=n>bs</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>microbatch_size</span> <span class=o>=</span> <span class=n>bs</span> <span class=o>//</span> <span class=n>accum_steps</span>
</span></span><span class=line><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Accumulating with microbatch_size </span><span class=si>%d</span><span class=s2> over </span><span class=si>%d</span><span class=s2> steps.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>microbatch_size</span><span class=p>,</span> <span class=n>accum_steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_microbatch</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>i</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>jax</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>map</span><span class=p>(</span>
</span></span><span class=line><span class=cl>          <span class=k>lambda</span> <span class=n>t</span><span class=p>:</span> <span class=n>jnp</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>t</span><span class=p>,</span> <span class=p>(</span><span class=n>accum_steps</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=n>t</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>:]))[</span><span class=n>i</span><span class=p>],</span> <span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Initialize accumulator.</span>
</span></span><span class=line><span class=cl>    <span class=n>l</span><span class=p>,</span> <span class=n>g</span> <span class=o>=</span> <span class=n>value_and_grad_fn</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>get_microbatch</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>accumulate</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>l_and_g</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>l</span><span class=p>,</span> <span class=n>g</span> <span class=o>=</span> <span class=n>l_and_g</span>
</span></span><span class=line><span class=cl>      <span class=n>l_i</span><span class=p>,</span> <span class=n>g_i</span> <span class=o>=</span> <span class=n>value_and_grad_fn</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>get_microbatch</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>i</span><span class=p>))</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=p>(</span><span class=n>l</span> <span class=o>+</span> <span class=n>l_i</span><span class=p>,</span> <span class=n>jax</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>jnp</span><span class=o>.</span><span class=n>add</span><span class=p>,</span> <span class=n>g</span><span class=p>,</span> <span class=n>g_i</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Average over accum_steps.</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=p>,</span> <span class=n>grads</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>lax</span><span class=o>.</span><span class=n>fori_loop</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>accum_steps</span><span class=p>,</span> <span class=n>accumulate</span><span class=p>,</span> <span class=p>(</span><span class=n>l</span><span class=p>,</span> <span class=n>g</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>jax</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span> <span class=o>/</span> <span class=n>accum_steps</span><span class=p>,</span> <span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>grads</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>value_and_grad_fn</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>batch</span><span class=p>)</span>
</span></span></code></pre></div><p>In theory, you could go all-in with many accumulation steps, such that the communication time as a fraction of total step time tends to zero - giving you an \(\eta \approx 99\%\).</p><p>In our case, we used 2 accumulation steps to match the 4096 batch-size in <a href=https://arxiv.org/abs/1912.11370 target=_blank rel=noreferrer>BiT: BigTransfer</a> paper. Plugging values back into our equation:</p><p>$$
\frac{2 \times T_s}{2 \times T_s + 0.5 \times T_c} = \frac{468}{468 + 53} \approx 89.8\%
$$</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/orion/gaccumulation.png alt="Gradient accumulation results" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Gradient accumulation results</figcaption></figure><p>Ouch, we were SO close to hit our \(90\%\) goal!</p><h2 id=3-faster-communication class="relative group">3. Faster Communication <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3-faster-communication aria-label=Anchor>#</a></span></h2><p>Ok, no scam going on here. We did <em>not</em> end up buying a faster NIC. Remember that our existing NIC had dual 10G ethernet ports - one of which was running on 1G for networking. We reconfigured all four servers to connect directly to the 10G switch, which in turn was connected to the Internet via a single 1G port.</p><p>On paper, we had 20G bandwidth to/from each node. The question was, did NCCL support multi-NIC? Absolutely it did! I will spare you the details of benchmarking, but these were the two flags we set for NCCL.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>NCCL_SOCKET_IFNAME</span><span class=o>=</span><span class=n>ens803f</span>  <span class=c1># Includes ens803f0 and ens803f1, 10G each.</span>
</span></span><span class=line><span class=cl><span class=n>NCCL_SOCKET_NTHREADS</span><span class=o>=</span><span class=mi>1</span>      <span class=c1># May be different on your setup.</span>
</span></span></code></pre></div><p>With communication speed doubled, we crunch the numbers again:</p><p>$$
\eta = \frac{2 \times T_s}{2 \times T_s + 0.25 \times T_c} = \frac{468}{468 + 27} \approx 94.5\%
$$</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/orion/multinic.png alt="Multi-NIC communication results" class="mx-auto my-0 rounded-md"><figcaption class=text-center>Multi-NIC communication results</figcaption></figure><h2 id=result class="relative group">Result <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#result aria-label=Anchor>#</a></span></h2><p>This cluster achieved a throughput roughly 20% higher than a $16/hr V100 AWS instance. Our team saved ~$120k for close to a year of uptime.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>We actually had an odd number of nodes. I rounded all calculations assuming 4, for it is a nice number for hardware.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://github.com/NVIDIA/nccl-tests/blob/master/doc/PERFORMANCE.md target=_blank rel=noreferrer>NCCL Bandwidth and Throughput Calculation</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://www.johndcook.com/blog/2018/11/15/bfloat16/ target=_blank rel=noreferrer>Comparing <code>bfloat16</code> range and precision to other 16-bit numbers</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/detr/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">PyTorch: Iâ€™m Fast, JAX: You Call That Fast?</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2024-08-16 00:00:00 +0000 UTC">16 August 2024</time>
</span></span></a></span><span><a class="group flex text-right" href=/posts/the-algorithm/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">The Algorithm</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2024-03-07 00:00:00 +0000 UTC">7 March 2024</time>
</span></span><span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div></footer></article></main><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12" id=to-top hidden=true><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div><footer class="py-10 print:hidden"><nav class="pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex list-none flex-col sm:flex-row"><li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0"><a href=/tags/ title=Tags><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">tags</span></a></li><li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0"><a href=https://drive.google.com/file/d/1blFQIqhagkHfd3sqsjawCyPCvl0Evrtw/view title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">cv</span></a></li></ul></nav><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">If you copy this, may your WiFi become unstable.</p></div><div class="flex flex-row items-center"><div class="me-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"><button id=appearance-switcher-0 type=button aria-label="appearance switcher"><div class="flex h-12 w-12 items-center justify-center dark:hidden" title="Switch to dark appearance"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="hidden h-12 w-12 items-center justify-center dark:flex" title="Switch to light appearance"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://masterskepticista.github.io/><div id=search-modal class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex flex-none items-center justify-between px-2"><form class="flex min-w-0 flex-auto items-center"><div class="flex h-8 w-8 items-center justify-center text-neutral-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto overflow-auto px-2"><ul id=search-results></ul></section></div></div></div></body></html>