<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#FFFFFF"><title>The Blessing of Dimensionality &#183; Home</title>
<meta name=title content="The Blessing of Dimensionality &#183; Home"><script type=text/javascript src=/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.e0c75b2446b3f8545af40deeeebc2b7899e8a610754fea305617e08710cee268.css integrity="sha256-4MdbJEaz+FRa9A3u7rwreJnophB1T+owVhfghxDO4mg="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.af5d9722112bedac95702865c340bcd6286c4e9b2c15ce26b531ea1fba974cb8.js integrity="sha256-r12XIhEr7ayVcChlw0C81ihsTpssFc4mtTHqH7qXTLg=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        &rsquo;nuff said about the curse of dimensionality
      
    "><link rel=canonical href=https://masterskepticista.github.io/posts/dimensionality/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://masterskepticista.github.io/posts/dimensionality/"><meta property="og:site_name" content="Home"><meta property="og:title" content="The Blessing of Dimensionality"><meta property="og:description" content="’nuff said about the curse of dimensionality"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-11T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-11T00:00:00+00:00"><meta property="article:tag" content="Dimensionality"><meta property="article:tag" content="Geometry"><meta property="article:tag" content="Neural Networks"><meta name=twitter:card content="summary"><meta name=twitter:title content="The Blessing of Dimensionality"><meta name=twitter:description content="’nuff said about the curse of dimensionality"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"The Blessing of Dimensionality","headline":"The Blessing of Dimensionality","abstract":"\u0026rsquo;nuff said about the curse of dimensionality","inLanguage":"en","url":"https:\/\/masterskepticista.github.io\/posts\/dimensionality\/","author":{"@type":"Person","name":"Karan Shah"},"copyrightYear":"2024","dateCreated":"2024-11-11T00:00:00\u002b00:00","datePublished":"2024-11-11T00:00:00\u002b00:00","dateModified":"2024-11-11T00:00:00\u002b00:00","keywords":["dimensionality","geometry","neural networks"],"mainEntityOfPage":"true","wordCount":"1028"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://masterskepticista.github.io/","name":"","position":1},{"@type":"ListItem","item":"https://masterskepticista.github.io/posts/","name":"Posts","position":2},{"@type":"ListItem","name":"The Blessing of Dimensionality","position":3}]}</script><meta name=author content="Karan Shah"><link href=https://masterskepticista.github.io/ rel=me><link href=https://github.com/MasterSkepticista rel=me><link href="https://scholar.google.com/citations?user=vEgcRTkAAAAJ&amp;hl=en" rel=me><link href=https://linkedin.com/in/karan-bhavesh-shah rel=me><link href=https://stackoverflow.com/users/9230398/karan-shah rel=me><link href=https://twitter.com/elevated_quark rel=me><link type=text/css rel=stylesheet href=/lib/katex/katex.min.68e17230ccd917b97b7a2def38a8108918599d8aa4f580bfb8cce5e13d23e4de43dcaba5f9000553cb2c10d0d1300aabfe5c433a3305ebd752609f0762a63e59.css integrity="sha512-aOFyMMzZF7l7ei3vOKgQiRhZnYqk9YC/uMzl4T0j5N5D3Kul+QAFU8ssENDRMAqr/lxDOjMF69dSYJ8HYqY+WQ=="><script defer src=/lib/katex/katex.min.50f14e69d6a8da7128ae3b63974c544ed377c36d096b5e3750f114e84c89d668b9301d9b0ed3248969aa183aa2e3bc4d2c1e73d5dcb7d462890c45a18d424589.js integrity="sha512-UPFOadao2nEorjtjl0xUTtN3w20Ja143UPEU6EyJ1mi5MB2bDtMkiWmqGDqi47xNLB5z1dy31GKJDEWhjUJFiQ=="></script><script defer src=/lib/katex/auto-render.min.6095714e3aadb63b14ddc4af69346ab12974c1b460654345f8d1860a0b68fcc51b22f68b757433193090bb80afc8965b65cb607e5541d0f5f0f4b2e64d69b9ff.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" onload=renderMathInElement(document.body)></script></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Home</a></div><ul class="flex list-none flex-col text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Blog</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/tags/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Tags</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><button id=search-button-1 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">The Blessing of Dimensionality</h1><div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2024-11-11 00:00:00 +0000 UTC">11 November 2024</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">5 mins</span></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 lg:sticky lg:top-10 print:hidden"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#data-as-a-manifold>Data as a Manifold</a></li><li><a href=#a-number-line>A Number Line</a></li><li><a href=#classification-in-2d>Classification in 2D</a></li><li><a href=#adding-the-third-dimension>Adding the third-dimension</a></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><p>Grant recently published a <a href="https://www.youtube.com/watch?v=piJkuavhV50" target=_blank rel=noreferrer>video</a> on how certain geometry puzzles become trivial to solve, when one additional dimension is available for the kind of geometry at hand. Math provides the necessary abstraction to think (and compute) in a dimensionality that far exceeds human imagination of 3 dimensions.</p><p>Modern foundation models use more than 10,000 feature vector dimensions. As of writing, few tools exist to understand what exactly happens in each of these dimensions. The goal of this post is not to explain what additional dimensions do, but to reason about how dimensionality affects learning, and <em>why</em> more dimensions typically yield better models. If you have read Chris Olah&rsquo;s decade-old post on <a href=https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/ target=_blank rel=noreferrer>manifold hypothesis</a>, first half of this post should be a cakewalk.</p><h2 id=data-as-a-manifold class="relative group">Data as a Manifold <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#data-as-a-manifold aria-label=Anchor>#</a></span></h2><p>Classification is a common deep learning task. Even foundation LLMs are trained on next-token prediction, which is a classification task. We can view classification as a way of transforming the data manifold into representations that can be sliced into individual classes.</p><blockquote><p>The manifold hypothesis is that natural data forms <strong>lower-dimensional manifolds</strong> in its embedding space. [&mldr;] If you believe this, then <strong>the task of a classification algorithm is fundamentally to separate a bunch of tangled manifolds.</strong></p></blockquote><p>Neural networks (NNs) are efficient at extracting representations from data by augmenting it into certain size of representations. Dimensionality of the representations that NNs extract from natural data depends on what is expected of them. For example, sentiment classification models may require a smaller data manifold, than say, summarizing it, if both models are trained from scratch until convergence.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>optax</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>flax.linen</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>jax</span><span class=o>,</span> <span class=nn>jax.numpy</span> <span class=k>as</span> <span class=nn>jnp</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>plotly.express</span> <span class=k>as</span> <span class=nn>px</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>plotly.graph_objects</span> <span class=k>as</span> <span class=nn>go</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rng</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>PRNGKey</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=a-number-line class="relative group">A Number Line <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#a-number-line aria-label=Anchor>#</a></span></h2><p>What better place to start an article like this with 1D space? Consider a simple binary classification problem. We have two classes, <code>0</code> and <code>1</code>, represented by three blobs on a number line. The inner blue blob is class <code>1</code>, and the outer red blobs are class <code>0</code>.</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/dimensionality/scatter1d.png alt="1D Scatter" class="mx-auto my-0 rounded-md"><figcaption class=text-center>1D Scatter</figcaption></figure><p>We know via the <a href=https://en.wikipedia.org/wiki/Universal_approximation_theorem target=_blank rel=noreferrer>universal approximation theorem</a>, that a neural network with at least one hidden layer (of arbitrary dimensionality) can approximate <strong>any</strong> function.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Brain</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Brain with a single hidden layer.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>dimensions</span><span class=p>:</span> <span class=nb>int</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nd>@nn.compact</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dimensions</span><span class=p>,</span> <span class=n>kernel_init</span><span class=o>=</span><span class=n>nn</span><span class=o>.</span><span class=n>initializers</span><span class=o>.</span><span class=n>xavier_uniform</span><span class=p>())(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>out</span><span class=p>[</span><span class=s2>&#34;activation&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>tanh</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&#34;classifier&#34;</span><span class=p>)(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>out</span>
</span></span></code></pre></div><p>On a number line, the only way to classify these two classes is to find a threshold value. This threshold value is the decision boundary.</p><p>We need some boilerplate to train this model. This is a vanilla SGD-based training loop with no fancy regularization or momentum.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=n>brain</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>params</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>jnp</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>jnp</span><span class=o>.</span><span class=n>ndarray</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Fit a classification model to the given data.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  <span class=nd>@jax.jit</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>train_step</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>opt_state</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>loss_fn</span><span class=p>(</span><span class=n>params</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>logits</span><span class=p>,</span> <span class=n>out</span> <span class=o>=</span> <span class=n>brain</span><span class=o>.</span><span class=n>apply</span><span class=p>({</span><span class=s2>&#34;params&#34;</span><span class=p>:</span> <span class=n>params</span><span class=p>},</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>logits</span> <span class=o>=</span> <span class=n>jnp</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=n>logits</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>loss</span> <span class=o>=</span> <span class=n>optax</span><span class=o>.</span><span class=n>sigmoid_binary_cross_entropy</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>      <span class=n>acc</span> <span class=o>=</span> <span class=n>jnp</span><span class=o>.</span><span class=n>mean</span><span class=p>((</span><span class=n>logits</span> <span class=o>&gt;</span> <span class=mf>0.5</span><span class=p>)</span> <span class=o>==</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;loss&#34;</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span> <span class=s2>&#34;acc&#34;</span><span class=p>:</span> <span class=n>acc</span><span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>loss</span><span class=p>,</span> <span class=p>(</span><span class=n>metrics</span><span class=p>,</span> <span class=n>out</span><span class=p>[</span><span class=s2>&#34;activation&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=n>_</span><span class=p>,</span> <span class=p>(</span><span class=n>metrics</span><span class=p>,</span> <span class=n>acts</span><span class=p>)),</span> <span class=n>grads</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>value_and_grad</span><span class=p>(</span><span class=n>loss_fn</span><span class=p>,</span> <span class=n>has_aux</span><span class=o>=</span><span class=kc>True</span><span class=p>)(</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>updates</span><span class=p>,</span> <span class=n>opt_state</span> <span class=o>=</span> <span class=n>tx</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>grads</span><span class=p>,</span> <span class=n>opt_state</span><span class=p>,</span> <span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span> <span class=o>=</span> <span class=n>optax</span><span class=o>.</span><span class=n>apply_updates</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>updates</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>params</span><span class=p>,</span> <span class=n>opt_state</span><span class=p>,</span> <span class=n>metrics</span><span class=p>,</span> <span class=n>acts</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  <span class=c1># Initialize optimizer</span>
</span></span><span class=line><span class=cl>  <span class=n>total_steps</span> <span class=o>=</span> <span class=mi>4_000</span>
</span></span><span class=line><span class=cl>  <span class=n>tx</span> <span class=o>=</span> <span class=n>optax</span><span class=o>.</span><span class=n>sgd</span><span class=p>(</span><span class=n>learning_rate</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>opt_state</span> <span class=o>=</span> <span class=n>tx</span><span class=o>.</span><span class=n>init</span><span class=p>(</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Training loop</span>
</span></span><span class=line><span class=cl>  <span class=n>step</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>total_steps</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span><span class=p>,</span> <span class=n>opt_state</span><span class=p>,</span> <span class=n>metrics</span><span class=p>,</span> <span class=n>acts</span> <span class=o>=</span> <span class=n>train_step</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>opt_state</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>step</span> <span class=o>%</span> <span class=mi>200</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>or</span> <span class=n>step</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Step </span><span class=si>{</span><span class=n>step</span><span class=si>}</span><span class=s1>, Loss: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;loss&#34;</span><span class=p>]</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>, Acc: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;acc&#34;</span><span class=p>]</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>params</span>
</span></span></code></pre></div><p>To match the 1D world of a number line, we will initialize our model with one dimension. The decision boundary of this neuron will be a point on the number line.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>brain</span> <span class=o>=</span> <span class=n>Brain</span><span class=p>(</span><span class=n>dimensions</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>rng</span><span class=p>,</span> <span class=n>rng_init</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>rng</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>brain</span><span class=o>.</span><span class=n>init</span><span class=p>(</span><span class=n>rng_init</span><span class=p>,</span> <span class=n>jnp</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>x</span><span class=p>))[</span><span class=s2>&#34;params&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>fit</span><span class=p>(</span><span class=n>brain</span><span class=p>,</span> <span class=n>params</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><p>Observe how the activation manifold evolves over time. Since we cannot go anywhere but left or right, the best-accuracy scenario is to push the blue blob as far away from the red blobs as possible, leaving half of red blobs wrongly classified. This gives exactly 75% accuracy.</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/dimensionality/manifold_1d.gif alt="1D Manifold Evolution" class="mx-auto my-0 rounded-md"><figcaption class=text-center>1D Manifold Evolution</figcaption></figure><p>But what if we could think in 2D? Ah, then the problem becomes trivial - we achieve 100% accuracy. Activation space is now a 2D plane, and the decision boundary is a line. Notice how blue cluster is stretched out orthogonally to the red blobs.</p><figure class="mx-auto my-0 rounded-md"><img src=/posts/dimensionality/manifold_1d_to_2d.gif alt="1D to 2D Manifold" class="mx-auto my-0 rounded-md"><figcaption class=text-center>1D to 2D Manifold</figcaption></figure><h2 id=classification-in-2d class="relative group">Classification in 2D <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#classification-in-2d aria-label=Anchor>#</a></span></h2><p>Let&rsquo;s redo this exercise, but starting in 2D space. Consider a binary classification problem where the inner blue blob is class <code>1</code>, and the red ring is class <code>0</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>make_circles</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span> <span class=n>noise</span><span class=o>=</span><span class=mf>0.15</span><span class=p>,</span> <span class=n>factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>x</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span> <span class=o>/</span> <span class=n>x</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fig</span> <span class=o>=</span> <span class=n>px</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>x</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>y</span><span class=o>=</span><span class=n>x</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>color_continuous_scale</span><span class=o>=</span><span class=s1>&#39;RdBu&#39;</span><span class=p>,</span> <span class=n>opacity</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=o>.</span><span class=n>update_layout</span><span class=p>(</span><span class=n>width</span><span class=o>=</span><span class=mi>600</span><span class=p>,</span> <span class=n>height</span><span class=o>=</span><span class=mi>600</span><span class=p>,</span> <span class=n>coloraxis_showscale</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>template</span><span class=o>=</span><span class=s2>&#34;plotly_white&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><figure class="mx-auto my-0 rounded-md"><img src=/posts/dimensionality/circles.png alt="2D Circles" class="mx-auto my-0 rounded-md"><figcaption class=text-center>2D Circles</figcaption></figure><p>To match the 2D world, we will initialize our model with two dimensions. Visualizing the activation manifold of this 2D model shows the learnt decision boundary. Since activation manifold is 2D, our decision boundary will be a line.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>brain</span> <span class=o>=</span> <span class=n>Brain</span><span class=p>(</span><span class=n>dimensions</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>rng</span><span class=p>,</span> <span class=n>rng_init</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>rng</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>brain</span><span class=o>.</span><span class=n>init</span><span class=p>(</span><span class=n>rng_init</span><span class=p>,</span> <span class=n>jnp</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>x</span><span class=p>))[</span><span class=s2>&#34;params&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>fit</span><span class=p>(</span><span class=n>brain</span><span class=p>,</span> <span class=n>params</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><figure class="mx-auto my-0 rounded-md"><img src=/posts/dimensionality/manifold_2d.gif alt="2D Manifold Evolution" class="mx-auto my-0 rounded-md"><figcaption class=text-center>2D Manifold Evolution</figcaption></figure><p>This behavior is similar to the case above where 1D line was expanded to 2D. The entire <code>blue</code> cluster is cornered with <code>red</code> ring stretched out along perpendicular directions. We achieve \(\sim\) 85% accuracy.</p><p>But we don&rsquo;t achieve 100% accuracy on this problem. No line segment can partition these two clusters in 2D space. The outer ring fully covers the inner one. It is mathematically impossible to do so, without using additional dimensions of space. The fact that despite topological limitations, this 2D model crossed \(\sim\) 85% on this dataset tells us how far even a 2D model can twist the data manifold for classification.</p><h2 id=adding-the-third-dimension class="relative group">Adding the third-dimension <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#adding-the-third-dimension aria-label=Anchor>#</a></span></h2><p>Let&rsquo;s see what happens when our model is given one extra dimension than the data manifold resides in. Our activation manifold will now be 3D.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>brain</span> <span class=o>=</span> <span class=n>Brain</span><span class=p>(</span><span class=n>dimensions</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>rng</span><span class=p>,</span> <span class=n>rng_init</span> <span class=o>=</span> <span class=n>jax</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>rng</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>brain</span><span class=o>.</span><span class=n>init</span><span class=p>(</span><span class=n>rng_init</span><span class=p>,</span> <span class=n>jnp</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>x</span><span class=p>))[</span><span class=s2>&#34;params&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>fit</span><span class=p>(</span><span class=n>brain</span><span class=p>,</span> <span class=n>params</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><p>The decision boundary is now a plane, which can separate the two classes with \(\sim\) 100% accuracy. This is because the model now stretches the center cluster out across z-axis, and slices a plane orthogonal to it.</p></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=flex><picture class="!mb-0 !mt-0 me-4 w-24 h-auto rounded-full"><img width=646 height=640 class="!mb-0 !mt-0 me-4 w-24 h-auto rounded-full" alt="Karan Shah" loading=lazy decoding=async src=/img/profile.png></picture><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Karan Shah</div><div class="text-sm text-neutral-700 dark:text-neutral-400">Sampling meaning from a non-stationary prior.</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://masterskepticista.github.io/ target=_blank aria-label=Link rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://github.com/MasterSkepticista target=_blank aria-label=Github rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href="https://scholar.google.com/citations?user=vEgcRTkAAAAJ&amp;hl=en" target=_blank aria-label=Google-Scholar rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg height="16" width="16" viewBox="0 0 512 512"><path fill="currentcolor" d="M390.9 298.5s0 .1.1.1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7 4.4-7.6 9.4-14.7 15-21.3 27.4-32.6 68.5-53.3 114.4-53.3 33.6.0 64.6 11.1 89.6 29.9 9.1 6.9 17.4 14.7 24.8 23.5 5.6 6.6 10.6 13.8 15 21.3 2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/></svg></span></a>
<a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://linkedin.com/in/karan-bhavesh-shah target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://stackoverflow.com/users/9230398/karan-shah target=_blank aria-label=Stack-Overflow rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 384 512"><path fill="currentcolor" d="M290.7 311 95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 3e2zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-2e2v39.7h2e2zm39.7 80H42.7V320h-40v160h359.5V320h-40z"/></svg>
</span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://twitter.com/elevated_quark target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span></a></div></div></div></div><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/graph-search/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Graph Search</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2024-08-27 00:00:00 +0000 UTC">27 August 2024</time>
</span></span></a></span><span><a class="group flex text-right" href=/posts/reduce-sum/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Embarrassingly Parallel Reduction in CUDA</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2025-02-19 00:00:00 +0000 UTC">19 February 2025</time>
</span></span><span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div></footer></article></main><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12" id=to-top hidden=true><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">Copyright © 2025 Karan Shah. If you copy this, may your WiFi become unstable.</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://masterskepticista.github.io/><div id=search-modal class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex flex-none items-center justify-between px-2"><form class="flex min-w-0 flex-auto items-center"><div class="flex h-8 w-8 items-center justify-center text-neutral-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto overflow-auto px-2"><ul id=search-results></ul></section></div></div></div></body></html>